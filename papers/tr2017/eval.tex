\section{Evaluation}
\label{sec:evaluate}

This section evaluates the costs of the various layers of abstraction
in our platform used to create the simplified end-to-end experience. 
We evaluate the cost of these layers using a set of micro-benchmarks, written
in both C++ and Static TypeScript, for three microcontrollers: nrF52, SAMD21 (CPX device), and Atmega (Uno).
The C++ benchmarks isolate the performance
of \CO and provide a baseline, while the Static TypeScript benchmarks show the overhead
added by \MC. 

\subsection{C++ and Static TypeScript runtime}
The C++ of our platform breaks into two essential layers:
\begin{itemize}
\item \emph{\CON-core}: the \CO device runtime, against which we write C++ programs;
\item \emph{\MCN-common-packages}: the C++ and Static TypeScript wrapping \CON-core 
to make it known to \MC, against which we write Static TypeScript programs;
\end{itemize}

The CPX runtime is the largest, as the CPX has lots of on-board
components; it shares much of its code with other SAMD21 \MC targets.
The compiled C++ runtime is 114k in total, with \CO accounting for 29k, with an
additional 15k from libmbed. The \MCN-common-packages adds 20k, but also pulls in
49k of the math support libraries (floating point operations,
including trigonometry and number printing/parsing).
As the SAMD21 has 256k of flash, this code was not heavily optimized for space.

On UNO, which has 32k of flash, the much less complete \MC runtime is 8k, and \CO is 14k.

The TypeScript part of the runtime is 1060 statements on CPX and 216 on UNO.
In our samples 99\% of that runtime is tree-shaken away.

\subsection{Compiling Static TypeScript}
% data generated using 'node map-file-stats.js CIRCUIT_PLAYGROUND.map'
% maybe put it in a table?

When compiling the Static TypeScript benchmarks and runtime with code shaking we obtain 
a generated code density of 37.5 bytes per statement on CPX, 60.8 on AVR native, and 12.3 on AVR VM.
This excludes string literals (which don't change the picture significantly), but includes class 
vtables and number literals if any. Note that ARM and AVR native instructions are 2 bytes each,
while AVR VM instructions are between 0.5 and 3 bytes.

When compiling, the entire TypeScript program, including the runtime, is
passed to the TypeScript (TS) language service for parsing. Then, only the remaining
part of the program (after code shaking) is compiled to native code.
On a modern laptop, using Node.js, TS parsing and analysis takes about 0.1ms per statement,
while \MC compilation to native code takes about 1ms per statement.
While the TS compiler has been optimized for speed, 
\MCN's native compilation process hasn't been.
For example, for CPX the TS pass is dominated by compile the device runtime 
and takes about 100ms, whereas the \MC pass typically only includes a small user program
and a small bit of the runtime, resulting in less than 100ms. 
Thus, typical compilation times are in the range of 200ms for user programs
of ABC-XYZ lines. 

The AVR VM was specifically designed for high code density, since the C++ runtime
leaves less than 10k for TS runtime and user code on the Uno.
The interpreter is implemented in assembly and always included with the program and is around 0.5k.
There are about 30 opcodes, some of which can take 1 or 2 byte arguments. 
There are also a few combined opcodes, representing a sequence of one argument-less opcode,
and one with an argument, which improves code density by about 25\%.
Opcodes are direct offsets into the code of the interpreter, speeding up execution.
They operate on a stack (mainly for function calls) and a special scratch register.
There is essentially no stack space overhead compared to native AVR compilation.
The speed overhead is around 4x-5x (with respect to native) for computational tasks.


%\subsection{Implementation}
% •	\CO (SAMD21 and AVR): base runtime (C++ only)
% •	pxt
% •	pxt-common-packages: C++ and Static TypeScript
% •	pxt-adafruit
% •	pxt-arduino-uno
% •	pxt-monaco, pxt-blockly

\subsection{FLASH and RAM footprint}

\begin{itemize}

 % FLASH and RAM footprint
\item FLASH footprint of the combined runtime codebase split by role (\CON-core, \MCN-common-packages)
% Analyse MAP file. (Assuming PXT core is in build, else Michal to provide size of PXT core libs)?
\item RAM footprint of the combined runtime codebase, also split by role; 
% (libc, codal-core, pxt-common-packages, makecode). Analyse MAP file for static footprint. 
%Enable HEAP\_DEBUG, and run C++ blinky and PXT blinky.
% cost of async/fibers/handlers
\item Scaling of RAM footprint with number of active fibers (parallel recursive calls in TS. 
%      Should be predictable, but validates we scale linearly and sets some hard figures 
%      for a real device). C++ test.
\end{itemize}

\subsection{Time for common \CO operations}

\begin{itemize}
\item Context switch time (both in real terms (uS) and CPU instructions). 
% C++ test, flipping a GPIO or two duting context switch and measuring on scope.
\item Event handling time (both in real terms (uS) and CPU instructions. 
%      Both IMMEDIATE and THREADED mode). C++ test. flipping a GPIO or two during context 
%      switch sections and measuring on scope.
\item Async Procedure Call (APC) handling time (both in real terms (uS) and CPU instructions). 
% C++ test. flipping a GPIO or two during context switch and measuring on scope.
\end{itemize}




%mmoskal [10:10 AM] 
%`pxt checkdocs --snippets --re perf --stats`
% [10:11] 
% I compile empty sample first twice, to reduce JIT costs
% [10:12] 
% also, the first "compile prep" is slightly more costly, since it parses a hex file

\begin{itemize}
\item Time taken to compile and link simple program in browser (can we use some existing apps 
      here as case studies? E.g. Smiley emoji and fireflies?
% microbenchmarks
% in addition, Arduino "examples"
% instrument via node? or shell?
\item \UF File Size comparisons to HEX and bin. Time taken to complete a UF2 flash operation 
    (c.f. equivalent DAPLINK flash on micro:bit and avrdude flash on uno?)
\end{itemize}

\subsection{C++, Native vs Bytecode}
% - program benchmarks for C++, compiled MakeCode, interpreted MakeCode
%     - APP: A simple blinky
%     - Measures CPU time, RAM, Flash consumption
\begin{itemize}
\item Tight loop performance of C++, TS, and Blocks e.g. flipping a GPIO. PXT native compile.
\item Tight loop performance of C++, TS, and Blocks e.g. flipping a GPIO. PXT bytecode interpreted.
\end{itemize}

\subsection{Hardware resources}

% - efficient use of hardware resources, compared to Arduino, which uses spin loops and doesn't always use the hardware (bit bangs instead)

